Run
1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.
npm
yarn
pnpm
bun

pnpm add @fal-ai/serverless-client
Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.

export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.

import * as fal from "@fal-ai/serverless-client";

const result = await fal.subscribe("fal-ai/aura-sr", {
  input: {
    image_url: "https://fal.media/files/rabbit/JlBgYUyQRS3zxiBu_B4fM.png"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.
API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import * as fal from "@fal-ai/serverless-client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.
3. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.
Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.
Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.
Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.

import * as fal from "@fal-ai/serverless-client";

// Upload a file (you can get a file reference from an input element or a drag-and-drop event)
const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);

// Use the URL in your request
const result = await fal.subscribe("fal-ai/aura-sr", { image_url: url });
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).
Read more about file handling in our file upload guide.
4. Schema
#
Input
#
image_url*string
URL of the image to upscale.
upscaling_factorUpscalingFactor(Xs)Enum
Upscaling factor. More coming soon. Default value: "4"

Possible enum values: 4
overlapping_tilesboolean
Whether to use overlapping tiles for upscaling. Setting this to true helps remove seams but doubles the inference time.
checkpointCheckpointEnum
Checkpoint to use for upscaling. More coming soon. Default value: "v1"

Possible enum values: v1, v2

{
  "image_url": "https://fal.media/files/rabbit/JlBgYUyQRS3zxiBu_B4fM.png",
  "upscaling_factor": 4,
  "overlapping_tiles": true,
  "checkpoint": "v2"
}
Output
#
image*Image
Upscaled image
timings*Timings
Timings for each step in the pipeline.

{
  "image": {
    "url": "",
    "content_type": "image/png",
    "file_name": "z9RV14K95DvU.png",
    "file_size": 4404019,
    "width": 1024,
    "height": 1024
  }
}
Other types
#
Image
#
url*string
The URL where the file can be downloaded from.
content_typestring
The mime type of the file.
file_namestring
The name of the file. It will be auto-generated if not provided.
file_sizeinteger
The size of the file in bytes.
file_datastring
File data
widthinteger
The width of the image in pixels.
heightinteger
The height of the image in pixels.

import fal_client
 
handler = fal_client.submit(
    "fal-ai/lora",
    arguments={
        "model_name": "stabilityai/stable-diffusion-xl-base-1.0",
        "prompt": "photo of a rhino dressed suit and tie sitting at a table in a bar with a bar stools, award winning photography, Elke vogelsang"
    },
)
 
result = handler.get()
print(result)

Project description
fal.ai Python client
This is a Python client library for interacting with ML models deployed on fal.ai.
Getting started
To install the client, run:
pip install fal-client
To use the client, you need to have an API key. You can get one by signing up at fal.ai. Once you have it, set it as an environment variable:
export FAL_KEY=your-api-key
Now you can use the client to interact with your models. Here's an example of how to use it:
import fal_client

response = fal_client.run("fal-ai/fast-sdxl", arguments={"prompt": "a cute cat, realistic, orange"})
print(response["images"][0]["url"])
Asynchronous requests
The client also supports asynchronous requests out of the box. Here's an example:
import asyncio
import fal_client

async def main():
    response = await fal_client.run_async("fal-ai/fast-sdxl", arguments={"prompt": "a cute cat, realistic, orange"})
    print(response["images"][0]["url"])


asyncio.run(main())
Uploading files
If the model requires files as input, you can upload them directly to fal.media (our CDN) and pass the URLs to the client. Here's an example:
import fal_client

audio_url = fal_client.upload_file("path/to/audio.wav")
response = fal_client.run("fal-ai/whisper", arguments={"audio_url": audio_url})
print(response["text"])
Encoding files as in-memory data URLs
If you don't want to upload your file to our CDN service (for latency reasons, for example), you can encode it as a data URL and pass it directly to the client. Here's an example:
import fal_client

audio_data_url = fal_client.encode_file("path/to/audio.wav")
response = fal_client.run("fal-ai/whisper", arguments={"audio_url": audio_data_url})
print(response["text"])
Queuing requests
When you want to send a request and keep receiving updates on its status, you can use the submit method. Here's an example:
import asyncio
import fal_client

async def main():
    response = await fal_client.submit_async("fal-ai/fast-sdxl", arguments={"prompt": "a cute cat, realistic, orange"})

    logs_index = 0
    async for event in response.iter_events(with_logs=True):
        if isinstance(event, fal_client.Queued):
            print("Queued. Position:", event.position)
        elif isinstance(event, (fal_client.InProgress, fal_client.Completed)):
            new_logs = event.logs[logs_index:]
            for log in new_logs:
                print(log["message"])
            logs_index = len(event.logs)

    result = await response.get()
    print(result["images"][0]["url"])


asyncio.run(main())


defaults for creativity upscale:

{
  "model_type": "SD_1_5",
  "image_url": "https://storage.googleapis.com/falserverless/model_tests/upscale/owl.png",
  "scale": 2,
  "creativity": 0.5,
  "detail": 1,
  "shape_preservation": 0.25,
  "prompt_suffix": " high quality, highly detailed, high resolution, sharp",
  "negative_prompt": "blurry, low resolution, bad, ugly, low quality, pixelated, interpolated, compression artifacts, noisey, grainy",
  "seed": 42,
  "guidance_scale": 7.5,
  "num_inference_steps": 20,
  "enable_safety_checks": true,
  "additional_lora_scale": 1
}